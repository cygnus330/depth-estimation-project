{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2585e2e6-ae07-431b-80da-46333dc2a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperPara config\n",
    "batch_size: int = 16\n",
    "epochs: int = 5\n",
    "\n",
    "# optimizer config\n",
    "learning_rate: float = 1.0e-4\n",
    "\n",
    "# dataset config\n",
    "is_conv = False\n",
    "model_save_dir: str = './models'\n",
    "model_name: str = 'unet_v1'\n",
    "num_workers: int = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774a18c4-bba4-4d42-b263-986a8b9b96e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n",
      "log at: models/Dec03_20-17-01_unet_v1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import codes.utils as util\n",
    "\n",
    "conv_image = None\n",
    "if is_conv:\n",
    "    def conv_image(src):\n",
    "        return conv.binary(src, val=255/2)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "totensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "start_time = datetime.now()\n",
    "time_str = start_time.strftime(\"%b%d_%H-%M-%S\")\n",
    "log_dir = os.path.join(\"models\", f\"{time_str}_{model_name}\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "assert(torch.cuda.is_available() == True)\n",
    "\n",
    "print(f\"Using CUDA device\")\n",
    "print(f\"log at: {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edb642a-3ab5-498a-95a3-cb80e3d6a426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded...\n"
     ]
    }
   ],
   "source": [
    "# 1. load model\n",
    "import codes.networks as network\n",
    "\n",
    "model = network.unet_v1()\n",
    "model = model.cuda()\n",
    "\n",
    "print(\"Model Loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9663c41-ffe2-4e3f-b00b-dad962105a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded...\n"
     ]
    }
   ],
   "source": [
    "# 2. load dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import codes.datas as data\n",
    "import codes.convs as conv\n",
    "\n",
    "train_dataset = data.nyu_v2_kaggle(dir='data/nyu2_train.csv', y_res=(60, 80), subset=conv_image)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "\n",
    "val_dataset = data.nyu_v2_kaggle(dir='data/nyu2_test.csv', y_res=(60, 80), subset=conv_image)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=True)\n",
    "\n",
    "print(\"Dataset Loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea439bfa-1035-4d19-9c13-ce20a4a90784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function Loaded...\n"
     ]
    }
   ],
   "source": [
    "# 3. load loss func\n",
    "import codes.loss as loss\n",
    "\n",
    "loss_fn = loss.RMSELoss().cuda()\n",
    "\n",
    "print(\"Loss Function Loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9b5c2d-4fbf-4064-8d55-585550726ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Loaded...\n"
     ]
    }
   ],
   "source": [
    "# 4. load optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, eps=1.0e-8)\n",
    "\n",
    "print(\"Optimizer Loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a20fda8-1b99-4617-95c2-c8bfdd673e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codes.utils as util\n",
    "\n",
    "x1 = util.read_image(\"data/nyu2_test/00001_colors.png\", 1, c=conv_image)\n",
    "x2 = util.read_image(\"data/nyu2_test/00974_colors.png\", 1, c=conv_image)\n",
    "x1_n = cv2.resize(cv2.imread(\"data/nyu2_test/00001_colors.png\", 1), (160, 120))\n",
    "x2_n = cv2.resize(cv2.imread(\"data/nyu2_test/00974_colors.png\", 1), (160, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab23f6df-2ccd-4793-ac42-2e7dbd624ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3168/3168 [02:50<00:00, 18.53batch/s, loss=0.7378]\n",
      "Validation 1: 100%|██████████| 40/40 [00:02<00:00, 19.97batch/s, Error=0.4450]\n",
      "Epoch 2: 100%|██████████| 3168/3168 [02:51<00:00, 18.52batch/s, loss=0.3825]\n",
      "Validation 2: 100%|██████████| 40/40 [00:02<00:00, 19.88batch/s, Error=0.2648]\n",
      "Epoch 3: 100%|██████████| 3168/3168 [02:50<00:00, 18.54batch/s, loss=0.1029]\n",
      "Validation 3: 100%|██████████| 40/40 [00:02<00:00, 19.70batch/s, Error=0.2347]\n",
      "Epoch 4: 100%|██████████| 3168/3168 [02:50<00:00, 18.56batch/s, loss=0.0457]\n",
      "Validation 4: 100%|██████████| 40/40 [00:02<00:00, 18.40batch/s, Error=0.2512]\n",
      "Epoch 5: 100%|██████████| 3168/3168 [02:50<00:00, 18.55batch/s, loss=0.0431]\n",
      "Validation 5: 100%|██████████| 40/40 [00:02<00:00, 19.37batch/s, Error=0.2492]\n"
     ]
    }
   ],
   "source": [
    "# 5. training\n",
    "model.train()\n",
    "print(f\"epochs: {epochs}\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # model train\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    batch_len = len(train_loader)\n",
    "    batch_runner = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "    for batch, data in enumerate(batch_runner, start=1):\n",
    "        t = torch.cuda.FloatTensor\n",
    "        x, y = data\n",
    "        x, y = Variable(x.type(t)), Variable(y.type(t))\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        batch_runner.set_postfix(loss=f\"{loss_sum / batch:.04f}\")\n",
    "\n",
    "    loss_avg = loss_sum / batch_len\n",
    "    writer.add_scalar('(Train) Loss/epoch', loss_avg, epoch)\n",
    "\n",
    "    # model val\n",
    "    model.eval()\n",
    "    error_sum = 0.0\n",
    "    batch_len = len(val_loader)\n",
    "    batch_runner = tqdm(val_loader, desc=f\"Validation {epoch}\", unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for batch, data in enumerate(batch_runner, start=1):\n",
    "            t = torch.cuda.FloatTensor\n",
    "            x, y = data\n",
    "            x, y = Variable(x.type(t)), Variable(y.type(t))\n",
    "\n",
    "            y_pred = model(x)\n",
    "            error = loss_fn(y_pred, y)\n",
    "\n",
    "            error_sum += error.item()\n",
    "            batch_runner.set_postfix(Error=f\"{error_sum / batch:.04f}\")\n",
    "\n",
    "        loss_avg = loss_sum / batch_len\n",
    "        error_avg = error_sum / batch_len\n",
    "        writer.add_scalar('(Val) Error/epoch', error_avg, epoch)\n",
    "\n",
    "    y1, y2 = model(x1.cuda()).cpu(), model(x2.cuda()).cpu()\n",
    "    y1, y2 = y1.detach().numpy().squeeze(), y2.detach().numpy().squeeze()\n",
    "    fig = util.make_plot(x1_n, y1, x2_n, y2)\n",
    "    fig = util.plot_to_img(fig)\n",
    "    writer.add_image(\"result(1, 974)\", fig, epoch)\n",
    "    \n",
    "    writer.flush()\n",
    "\n",
    "    # model save\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "        \n",
    "    dir_to_save = os.path.join(log_dir, f'epoch_{epoch}.pth')\n",
    "    torch.save(model.state_dict(), dir_to_save)\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6fa32-8fd5-4c40-b6ba-0a70334f6c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
